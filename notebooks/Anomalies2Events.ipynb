{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "import transformers\n",
    "from transformers import pipeline\n",
    "\n",
    "import sentence_transformers \n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANOMALY_DATA = '/mnt/ess_storage/DN_1/storage/home/mkovalchuk/instagram/event_data/anomalies/nyc_anomalies.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_an = pd.read_csv(ANOMALY_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>caption</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>author_id</th>\n",
       "      <th>location_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>city</th>\n",
       "      <th>event_ind</th>\n",
       "      <th>event_title</th>\n",
       "      <th>noise_probability</th>\n",
       "      <th>event_utility</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BsF2SIgHY8a</td>\n",
       "      <td>After hours heading into the after after @barc...</td>\n",
       "      <td>40.672100</td>\n",
       "      <td>-74.213660</td>\n",
       "      <td>388546074</td>\n",
       "      <td>795973886</td>\n",
       "      <td>1546344616</td>\n",
       "      <td>nyc</td>\n",
       "      <td>0</td>\n",
       "      <td>@boris</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BsF6Oo9IOcW</td>\n",
       "      <td>@7 am jersey  @boris.transmit  Strong üí™ #sound...</td>\n",
       "      <td>40.672100</td>\n",
       "      <td>-74.213660</td>\n",
       "      <td>745341106</td>\n",
       "      <td>795973886</td>\n",
       "      <td>1546346783</td>\n",
       "      <td>nyc</td>\n",
       "      <td>0</td>\n",
       "      <td>@boris</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BsF4_8jAKjb</td>\n",
       "      <td>KEEP GOING UP!\\nWhat an awesome year we‚Äôve had...</td>\n",
       "      <td>40.679026</td>\n",
       "      <td>-74.162631</td>\n",
       "      <td>248540046</td>\n",
       "      <td>450847625439125</td>\n",
       "      <td>1546345948</td>\n",
       "      <td>nyc</td>\n",
       "      <td>1</td>\n",
       "      <td>#happynewyear</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BsF4_9Rg3Vn</td>\n",
       "      <td>______________________________________________...</td>\n",
       "      <td>40.679026</td>\n",
       "      <td>-74.162631</td>\n",
       "      <td>8724527186</td>\n",
       "      <td>450847625439125</td>\n",
       "      <td>1546345911</td>\n",
       "      <td>nyc</td>\n",
       "      <td>1</td>\n",
       "      <td>#happynewyear</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BsF52frB5Cq</td>\n",
       "      <td>welcome January 2‚ù§Ô∏è19\\nfirst  New2‚ù§Ô∏è19 Years d...</td>\n",
       "      <td>40.679026</td>\n",
       "      <td>-74.162631</td>\n",
       "      <td>1741794379</td>\n",
       "      <td>450847625439125</td>\n",
       "      <td>1546346358</td>\n",
       "      <td>nyc</td>\n",
       "      <td>1</td>\n",
       "      <td>#happynewyear</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BsF5qmcna-_</td>\n",
       "      <td>Cherry Pie, Nr. 542.\\nHall√∂chen #2k19 üéà ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî...</td>\n",
       "      <td>40.679026</td>\n",
       "      <td>-74.162631</td>\n",
       "      <td>4350877101</td>\n",
       "      <td>450847625439125</td>\n",
       "      <td>1546346261</td>\n",
       "      <td>nyc</td>\n",
       "      <td>1</td>\n",
       "      <td>#happynewyear</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BsF7fWYgbnw</td>\n",
       "      <td>Happy new year from the new member of Momoland...</td>\n",
       "      <td>40.679026</td>\n",
       "      <td>-74.162631</td>\n",
       "      <td>3680842901</td>\n",
       "      <td>450847625439125</td>\n",
       "      <td>1546347217</td>\n",
       "      <td>nyc</td>\n",
       "      <td>1</td>\n",
       "      <td>#happynewyear</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BsF149vAqOb</td>\n",
       "      <td>#CAF_DUBAI\\n@nostalgiadubai</td>\n",
       "      <td>40.718450</td>\n",
       "      <td>-73.997880</td>\n",
       "      <td>9939430382</td>\n",
       "      <td>1552494681453358</td>\n",
       "      <td>1546344281</td>\n",
       "      <td>nyc</td>\n",
       "      <td>2</td>\n",
       "      <td>@nostalgiadubai</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BsF1wSCgceJ</td>\n",
       "      <td>#CAF_DUBAI\\n@nostalgiadubai</td>\n",
       "      <td>40.718450</td>\n",
       "      <td>-73.997880</td>\n",
       "      <td>9939430382</td>\n",
       "      <td>1552494681453358</td>\n",
       "      <td>1546344210</td>\n",
       "      <td>nyc</td>\n",
       "      <td>2</td>\n",
       "      <td>@nostalgiadubai</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BsF7xD_hYo5</td>\n",
       "      <td>Happy New Year! We are so proud to be a part o...</td>\n",
       "      <td>40.718712</td>\n",
       "      <td>-73.999500</td>\n",
       "      <td>199996532</td>\n",
       "      <td>1535965</td>\n",
       "      <td>1546347411</td>\n",
       "      <td>nyc</td>\n",
       "      <td>2</td>\n",
       "      <td>@nostalgiadubai</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          code                                            caption        lat  \\\n",
       "0  BsF2SIgHY8a  After hours heading into the after after @barc...  40.672100   \n",
       "1  BsF6Oo9IOcW  @7 am jersey  @boris.transmit  Strong üí™ #sound...  40.672100   \n",
       "2  BsF4_8jAKjb  KEEP GOING UP!\\nWhat an awesome year we‚Äôve had...  40.679026   \n",
       "3  BsF4_9Rg3Vn  ______________________________________________...  40.679026   \n",
       "4  BsF52frB5Cq  welcome January 2‚ù§Ô∏è19\\nfirst  New2‚ù§Ô∏è19 Years d...  40.679026   \n",
       "5  BsF5qmcna-_  Cherry Pie, Nr. 542.\\nHall√∂chen #2k19 üéà ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî...  40.679026   \n",
       "6  BsF7fWYgbnw  Happy new year from the new member of Momoland...  40.679026   \n",
       "7  BsF149vAqOb                        #CAF_DUBAI\\n@nostalgiadubai  40.718450   \n",
       "8  BsF1wSCgceJ                        #CAF_DUBAI\\n@nostalgiadubai  40.718450   \n",
       "9  BsF7xD_hYo5  Happy New Year! We are so proud to be a part o...  40.718712   \n",
       "\n",
       "         lon   author_id       location_id   timestamp city  event_ind  \\\n",
       "0 -74.213660   388546074         795973886  1546344616  nyc          0   \n",
       "1 -74.213660   745341106         795973886  1546346783  nyc          0   \n",
       "2 -74.162631   248540046   450847625439125  1546345948  nyc          1   \n",
       "3 -74.162631  8724527186   450847625439125  1546345911  nyc          1   \n",
       "4 -74.162631  1741794379   450847625439125  1546346358  nyc          1   \n",
       "5 -74.162631  4350877101   450847625439125  1546346261  nyc          1   \n",
       "6 -74.162631  3680842901   450847625439125  1546347217  nyc          1   \n",
       "7 -73.997880  9939430382  1552494681453358  1546344281  nyc          2   \n",
       "8 -73.997880  9939430382  1552494681453358  1546344210  nyc          2   \n",
       "9 -73.999500   199996532           1535965  1546347411  nyc          2   \n",
       "\n",
       "       event_title  noise_probability  event_utility  \n",
       "0           @boris                  0              1  \n",
       "1           @boris                  0              1  \n",
       "2    #happynewyear                  0              1  \n",
       "3    #happynewyear                  0              1  \n",
       "4    #happynewyear                  0              1  \n",
       "5    #happynewyear                  0              1  \n",
       "6    #happynewyear                  0              1  \n",
       "7  @nostalgiadubai                  0              1  \n",
       "8  @nostalgiadubai                  0              1  \n",
       "9  @nostalgiadubai                  0              1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_an.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>caption</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>author_id</th>\n",
       "      <th>location_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>city</th>\n",
       "      <th>event_title</th>\n",
       "      <th>noise_probability</th>\n",
       "      <th>event_utility</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>event_ind</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893933</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893934</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893935</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893936</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893937</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>893938 rows √ó 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           code  caption  lat  lon  author_id  location_id  timestamp  city  \\\n",
       "event_ind                                                                     \n",
       "0             2        2    2    2          2            2          2     2   \n",
       "1             5        5    5    5          5            5          5     5   \n",
       "2             3        3    3    3          3            3          3     3   \n",
       "3             2        2    2    2          2            2          2     2   \n",
       "4             2        2    2    2          2            2          2     2   \n",
       "...         ...      ...  ...  ...        ...          ...        ...   ...   \n",
       "893933        9        9    9    9          9            9          9     9   \n",
       "893934        8        8    8    8          8            8          8     8   \n",
       "893935        2        2    2    2          2            2          2     2   \n",
       "893936        6        6    6    6          6            6          6     6   \n",
       "893937        2        2    2    2          2            2          2     2   \n",
       "\n",
       "           event_title  noise_probability  event_utility  \n",
       "event_ind                                                 \n",
       "0                    2                  2              2  \n",
       "1                    5                  5              5  \n",
       "2                    3                  3              3  \n",
       "3                    2                  2              2  \n",
       "4                    2                  2              2  \n",
       "...                ...                ...            ...  \n",
       "893933               9                  9              9  \n",
       "893934               8                  8              8  \n",
       "893935               2                  2              2  \n",
       "893936               6                  6              6  \n",
       "893937               2                  2              2  \n",
       "\n",
       "[893938 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_an.groupby(by='event_ind').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Quantization analysis for different topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 building vectors based on caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = model.encode(df_an.caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VECTOR_PATH = '/mnt/ess_storage/DN_1/storage/home/akorneev/temp_tables/orig_vectors.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save vectors to file in oder to use rapids environment\n",
    "np.save(VECTOR_PATH, vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 umap to decrease dimensionality [https://arxiv.org/abs/1802.03426] (Used with 'rapids' kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.rapids.ai/api/cuml/stable/api.html\n",
    "from cuml import UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = np.load(VECTOR_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 384)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to do: determine number of components according to the information loss using PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_model = UMAP(n_neighbors = 300, min_dist = 0.01, n_components = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_vectors = umap_model.fit_transform(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 300)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('umap_vectors.npy', new_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 vectors clustering to define topics (Used with 'rapids' kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset after kernel changing\n",
    "import pandas as pd\n",
    "ANOMALY_DATA = '/mnt/ess_storage/DN_1/storage/home/mkovalchuk/instagram/event_data/anomalies/nyc_anomalies.csv'\n",
    "df_an = pd.read_csv(ANOMALY_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer  \n",
    "\n",
    "transformer = TfidfTransformer()\n",
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keywords_from_cluster(labels_, df, top_k):\n",
    "    df['label'] = pd.Series(labels_)\n",
    "    corpus = list()\n",
    "    for lab in set(labels_):\n",
    "        corpus.append(str(df[df.label == lab].dropna().caption.sum()).lower().replace('\\n', ' '))\n",
    "    \n",
    "    tfidf = transformer.fit_transform(vectorizer.fit_transform(corpus))\n",
    "    words = vectorizer.get_feature_names() \n",
    "    weight = tfidf.toarray() \n",
    "    \n",
    "    for id, lab in enumerate(set(labels_)):\n",
    "        nums = weight[id].argsort()[-top_k:]\n",
    "        print(\"lab\", lab, \":\", [words[i] for i in nums])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1 HDBSCAN (to find number of classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuml.cluster import HDBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdbscan_model = HDBSCAN(min_cluster_size = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label prop iterations: 13\n",
      "Label prop iterations: 6\n",
      "Label prop iterations: 4\n",
      "Label prop iterations: 3\n",
      "Iterations: 4\n",
      "4778,133,127,13,210,950\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HDBSCAN()"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdbscan_model.fit(new_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 22\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of classes:\", hdbscan_model.cluster_persistence_[0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noisy count: 522\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique( hdbscan_model.labels_, return_counts=True)\n",
    "print(\"Noisy count:\", dict(zip(unique, counts))[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lab 0 : ['york', 'year', 'new', 'in', 'the']\n",
      "lab 1 : ['new', 'and', 'you', 'year', 'to']\n",
      "lab 2 : ['nyewhat', 'playinfaces', 'last', 'friends', 'night']\n",
      "lab 3 : ['igers', 'instalike', 'instagood', 'iger', 'instagram']\n",
      "lab 4 : ['happynewyear', 'newyorkmoments', 'topmodels', 'bygregory', 'fashionishope']\n",
      "lab 5 : ['vasilopita', 'greek', 'sweets', 'the', 'it']\n",
      "lab 6 : ['bartender', 'get', 'nochesdepartys', 'website', 'photos']\n",
      "lab 7 : ['to', 'year', 'workout', 'the', 'fitness']\n",
      "lab 8 : ['it', 'and', 'you', 'the', 'to']\n",
      "lab 9 : ['to', 'happynewyear', '2019', 'new', 'year']\n",
      "lab 10 : ['happy', 'to', 'year', 'closed', 'we']\n",
      "lab 11 : ['ringing', 'year', 'in', 'new', 'the']\n",
      "lab 12 : ['to', 'ny', 'the', 'music', 'dj']\n",
      "lab 13 : ['namjoonie', 'follow4followback', 'bighitofficial', 'l4l', 'bts']\n",
      "lab 14 : ['and', 'the', 'new', 'brunch', 'year']\n",
      "lab 15 : ['con', 'nuestro', 'grupaso', 'encendio', 'urbanda']\n",
      "lab 16 : ['bottles', 'dj', '8am', 'till', 'party']\n",
      "lab 17 : ['of', 'chicken', 'delicious', 'food', 'and']\n",
      "lab 18 : ['inkandpen', 'tattoodesign', 'klompchinggallery', 'nycmagazine', 'anzystories']\n",
      "lab 19 : ['crushloungenyc', 'twostrandtwist', 'vsco', 'miguelabreugallery', 'shotoniphone']\n",
      "lab 20 : ['ÎäêÍª¥ÏßÄÎäî', 'Îß•ÎùºÏù¥Ïñ∏Ïù¥', 'Îâ¥ÏöïÏòÅÌôî', 'Ïú†Î∏åÍ∞ìÎ©îÏùº', 'ilovenewyork']\n",
      "lab 21 : ['bnw', 'sonyalphaphotos', 'sonyvisuals', 'bridge', 'the']\n",
      "lab -1 : ['to', 'new', 'year', 'and', 'the']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10203/3584047051.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['label'] = pd.Series(labels_)\n",
      "/home/jovyan/.conda/envs/rapids-22.02/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "get_keywords_from_cluster(hdbscan_model.labels_, df_an[:1000], 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2 K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.3 Agglomerative Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 quantization analysis for obtained clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Similarity calculating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_time(time1, time2):\n",
    "    # check wich cluster it is, chose time shift\n",
    "    return 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_space(space1, space2):\n",
    "    # check wich cluster it is, chose space shift\n",
    "    return 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_semantic(text1, text2):\n",
    "    return 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarity(row1, row2):\n",
    "    # + —Ä–µ–∫–ª–∞–º–∞\n",
    "    total = connect_time(row1.timestamp, row2.timestamp) + connect_space((row1.lat, row1.lon), (row2.lat, row2.lon)) + connect_semantic(row1.caption, row2.caption)\n",
    "    return float (total) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_similarity(df_an.iloc[0], df_an.iloc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –≥—Ä–∞—Ñ —Å–æ —Å–≤—è–∑–∫–æ–π –∞–Ω–æ–º–∞–ª–∏–π?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

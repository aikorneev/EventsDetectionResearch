{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "import transformers\n",
    "from transformers import pipeline\n",
    "\n",
    "import sentence_transformers \n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_df():\n",
    "    ANOMALY_DATA = '/mnt/ess_storage/DN_1/storage/home/mkovalchuk/instagram/event_data/anomalies/nyc_anomalies.csv'\n",
    "    df = pd.read_csv(ANOMALY_DATA)\n",
    "    df = df.dropna(subset = ['caption']).reset_index(drop=True)\n",
    "    df.caption = df.caption.apply(lambda x: x.replace('\\n', ' ') if type(x) != float else print(x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_an = prepare_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>caption</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>author_id</th>\n",
       "      <th>location_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>city</th>\n",
       "      <th>event_title</th>\n",
       "      <th>noise_probability</th>\n",
       "      <th>event_utility</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>event_ind</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893933</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893934</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893935</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893936</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893937</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>893938 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           code  caption  lat  lon  author_id  location_id  timestamp  city  \\\n",
       "event_ind                                                                     \n",
       "0             2        2    2    2          2            2          2     2   \n",
       "1             5        5    5    5          5            5          5     5   \n",
       "2             3        3    3    3          3            3          3     3   \n",
       "3             2        2    2    2          2            2          2     2   \n",
       "4             2        2    2    2          2            2          2     2   \n",
       "...         ...      ...  ...  ...        ...          ...        ...   ...   \n",
       "893933        9        9    9    9          9            9          9     9   \n",
       "893934        8        8    8    8          8            8          8     8   \n",
       "893935        2        2    2    2          2            2          2     2   \n",
       "893936        6        6    6    6          6            6          6     6   \n",
       "893937        2        2    2    2          2            2          2     2   \n",
       "\n",
       "           event_title  noise_probability  event_utility  \n",
       "event_ind                                                 \n",
       "0                    2                  2              2  \n",
       "1                    5                  5              5  \n",
       "2                    3                  3              3  \n",
       "3                    2                  2              2  \n",
       "4                    2                  2              2  \n",
       "...                ...                ...            ...  \n",
       "893933               9                  9              9  \n",
       "893934               8                  8              8  \n",
       "893935               2                  2              2  \n",
       "893936               6                  6              6  \n",
       "893937               2                  2              2  \n",
       "\n",
       "[893938 rows x 11 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_an.groupby(by='event_ind').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Quantization analysis for different topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 building vectors based on caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "VECTOR_PATH = '/mnt/ess_storage/DN_1/storage/home/akorneev/temp_tables/orig_vectors'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!rm /mnt/ess_storage/DN_1/storage/home/akorneev/temp_tables/orig_vectors*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5077436, 13)"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_an.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>caption</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>author_id</th>\n",
       "      <th>location_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>city</th>\n",
       "      <th>event_ind</th>\n",
       "      <th>event_title</th>\n",
       "      <th>noise_probability</th>\n",
       "      <th>event_utility</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B1L2tB5nQmL</td>\n",
       "      <td>#facts don’t let the fear of what others think...</td>\n",
       "      <td>40.696340</td>\n",
       "      <td>-74.269510</td>\n",
       "      <td>6341874</td>\n",
       "      <td>43021175</td>\n",
       "      <td>1565873387</td>\n",
       "      <td>nyc</td>\n",
       "      <td>370422</td>\n",
       "      <td>#buysellrentrealestate</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B9mczOBB7GP</td>\n",
       "      <td>EDIT: I’m just gonna stay home and reach my fu...</td>\n",
       "      <td>40.706669</td>\n",
       "      <td>-73.990302</td>\n",
       "      <td>2929432</td>\n",
       "      <td>6639340</td>\n",
       "      <td>1583945645</td>\n",
       "      <td>nyc</td>\n",
       "      <td>786714</td>\n",
       "      <td>#bookstore</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BslNzU-B6r9</td>\n",
       "      <td>THIS SUNDAY is our NYC Premiere Party and we a...</td>\n",
       "      <td>40.745639</td>\n",
       "      <td>-73.988150</td>\n",
       "      <td>5773679940</td>\n",
       "      <td>474165</td>\n",
       "      <td>1547397005</td>\n",
       "      <td>nyc</td>\n",
       "      <td>16555</td>\n",
       "      <td>#salsascene</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BurjGbQF_GG</td>\n",
       "      <td>Wednesdays &amp; Thursdays mean @melissaboo_ @pros...</td>\n",
       "      <td>40.675060</td>\n",
       "      <td>-73.966870</td>\n",
       "      <td>4417594876</td>\n",
       "      <td>593978934118650</td>\n",
       "      <td>1551904505</td>\n",
       "      <td>nyc</td>\n",
       "      <td>93396</td>\n",
       "      <td>#groupyogaclasses</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B6kBPZ1p0Y7</td>\n",
       "      <td>A pocos días de terminar este 2019 y no dejo d...</td>\n",
       "      <td>40.713240</td>\n",
       "      <td>-74.015193</td>\n",
       "      <td>2925298960</td>\n",
       "      <td>171406</td>\n",
       "      <td>1577421636</td>\n",
       "      <td>nyc</td>\n",
       "      <td>625417</td>\n",
       "      <td>#911memorial</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846234</th>\n",
       "      <td>B14zuwVA7op</td>\n",
       "      <td>Things got wild at #ezoo2019 ! Good to be back...</td>\n",
       "      <td>40.794448</td>\n",
       "      <td>-73.924084</td>\n",
       "      <td>11299085</td>\n",
       "      <td>442488</td>\n",
       "      <td>1567381778</td>\n",
       "      <td>nyc</td>\n",
       "      <td>403348</td>\n",
       "      <td>#ezoo</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846235</th>\n",
       "      <td>B4ETix7hFqG</td>\n",
       "      <td>Happy Dinner Time @chinabluenyc</td>\n",
       "      <td>40.724040</td>\n",
       "      <td>-74.009960</td>\n",
       "      <td>189722955</td>\n",
       "      <td>218279866</td>\n",
       "      <td>1572062523</td>\n",
       "      <td>nyc</td>\n",
       "      <td>507805</td>\n",
       "      <td>@baje_infamy</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846236</th>\n",
       "      <td>B3k6MHEHOY6</td>\n",
       "      <td>The moment @djamenra noticed a 🌈 glistening on...</td>\n",
       "      <td>40.722340</td>\n",
       "      <td>-74.046990</td>\n",
       "      <td>33409529</td>\n",
       "      <td>248388855630908</td>\n",
       "      <td>1571009043</td>\n",
       "      <td>nyc</td>\n",
       "      <td>484100</td>\n",
       "      <td>@jcfamilies</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846237</th>\n",
       "      <td>BwfQ_4fl65k</td>\n",
       "      <td>🥞🥞 Just a cute stack of blueberry compote panc...</td>\n",
       "      <td>40.741780</td>\n",
       "      <td>-73.990510</td>\n",
       "      <td>7887446775</td>\n",
       "      <td>630389650455954</td>\n",
       "      <td>1555787289</td>\n",
       "      <td>nyc</td>\n",
       "      <td>168272</td>\n",
       "      <td>#italianliterature</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846238</th>\n",
       "      <td>B45-aAuAdky</td>\n",
       "      <td>This is so real it tugs at my soul.  I’ve neve...</td>\n",
       "      <td>40.882100</td>\n",
       "      <td>-73.848600</td>\n",
       "      <td>7556847098</td>\n",
       "      <td>1685326581761685</td>\n",
       "      <td>1573863381</td>\n",
       "      <td>nyc</td>\n",
       "      <td>549385</td>\n",
       "      <td>#mommyblogger</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>846239 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               code                                            caption  \\\n",
       "0       B1L2tB5nQmL  #facts don’t let the fear of what others think...   \n",
       "1       B9mczOBB7GP  EDIT: I’m just gonna stay home and reach my fu...   \n",
       "2       BslNzU-B6r9  THIS SUNDAY is our NYC Premiere Party and we a...   \n",
       "3       BurjGbQF_GG  Wednesdays & Thursdays mean @melissaboo_ @pros...   \n",
       "4       B6kBPZ1p0Y7  A pocos días de terminar este 2019 y no dejo d...   \n",
       "...             ...                                                ...   \n",
       "846234  B14zuwVA7op  Things got wild at #ezoo2019 ! Good to be back...   \n",
       "846235  B4ETix7hFqG                    Happy Dinner Time @chinabluenyc   \n",
       "846236  B3k6MHEHOY6  The moment @djamenra noticed a 🌈 glistening on...   \n",
       "846237  BwfQ_4fl65k  🥞🥞 Just a cute stack of blueberry compote panc...   \n",
       "846238  B45-aAuAdky  This is so real it tugs at my soul.  I’ve neve...   \n",
       "\n",
       "              lat        lon   author_id       location_id   timestamp city  \\\n",
       "0       40.696340 -74.269510     6341874          43021175  1565873387  nyc   \n",
       "1       40.706669 -73.990302     2929432           6639340  1583945645  nyc   \n",
       "2       40.745639 -73.988150  5773679940            474165  1547397005  nyc   \n",
       "3       40.675060 -73.966870  4417594876   593978934118650  1551904505  nyc   \n",
       "4       40.713240 -74.015193  2925298960            171406  1577421636  nyc   \n",
       "...           ...        ...         ...               ...         ...  ...   \n",
       "846234  40.794448 -73.924084    11299085            442488  1567381778  nyc   \n",
       "846235  40.724040 -74.009960   189722955         218279866  1572062523  nyc   \n",
       "846236  40.722340 -74.046990    33409529   248388855630908  1571009043  nyc   \n",
       "846237  40.741780 -73.990510  7887446775   630389650455954  1555787289  nyc   \n",
       "846238  40.882100 -73.848600  7556847098  1685326581761685  1573863381  nyc   \n",
       "\n",
       "        event_ind             event_title  noise_probability  event_utility  \n",
       "0          370422  #buysellrentrealestate                  0              1  \n",
       "1          786714              #bookstore                  0              1  \n",
       "2           16555             #salsascene                  0              1  \n",
       "3           93396       #groupyogaclasses                  0              1  \n",
       "4          625417            #911memorial                  0              1  \n",
       "...           ...                     ...                ...            ...  \n",
       "846234     403348                   #ezoo                  0              1  \n",
       "846235     507805            @baje_infamy                  0              1  \n",
       "846236     484100             @jcfamilies                  0              1  \n",
       "846237     168272      #italianliterature                  0              1  \n",
       "846238     549385           #mommyblogger                  0              1  \n",
       "\n",
       "[846239 rows x 12 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we randomly use only 1\\6 of anomalies because of computational recources limitations\n",
    "df_cut = df_an.sample(int(df_an.shape[0]/6), random_state = 2022, ignore_index = True)\n",
    "df_cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors_cut = model.encode(df_cut.caption.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(VECTOR_PATH + '_cut', vectors_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1000000\n",
      "1000000 2000000\n",
      "2000000 3000000\n",
      "3000000 4000000\n",
      "4000000 5000000\n",
      "5000000 5077436\n",
      "CPU times: user 3h 25min 8s, sys: 54min 43s, total: 4h 19min 52s\n",
      "Wall time: 2h 24min 12s\n"
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "# step by step encoding to control the process\n",
    "#old_i = 0\n",
    "#step = 1000000\n",
    "#for i in range(step, df_an.shape[0], step):\n",
    "#    print(old_i, i)\n",
    "#    vectors = model.encode(df_an.caption.tolist()[old_i:i])\n",
    "#    np.save(VECTOR_PATH + str(i), vectors)\n",
    "#    old_i = i\n",
    "#\n",
    "#print(i, df_an.shape[0])\n",
    "#vectors = model.encode(df_an.caption.tolist()[i:df_an.shape[0]])\n",
    "#np.save(VECTOR_PATH + str(df_an.shape[0]), vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2.1 PCA to decrease dimensionality and calculate information loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=vectors.shape[1], svd_solver='full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors_transformed = pca.fit(vectors).transform(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f5c44fcfbe0>]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "explained_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "plt.plot(np.arange(vectors.shape[1]), explained_variance, ls = '-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# minimal number of components to exceed 95%\n",
    "comp_num = next(x[0] for x in enumerate(explained_variance) if x[1] > 0.95) + 1\n",
    "comp_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2.2 umap to decrease dimensionality [https://arxiv.org/abs/1802.03426 ] (Used with 'rapids' kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset after kernel changing\n",
    "import pandas as pd\n",
    "df_an = prepare_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cut = df_an.sample(int(df_an.shape[0]/6), random_state = 2022, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "VECTOR_PATH = '/mnt/ess_storage/DN_1/storage/home/akorneev/temp_tables/orig_vectors'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading\n",
    "#old_i = 0\n",
    "#step = 1000000\n",
    "#vectors_list = list()\n",
    "#for i in range(step, df_an.shape[0], step):\n",
    "#    vectors_list.append(np.load(VECTOR_PATH + str(i) + \".npy\"))\n",
    "#vectors_list.append(np.load(VECTOR_PATH + str(df_an.shape[0]) + \".npy\"))\n",
    "#vectors = np.concatenate([ vec for vec in vectors_list ])\n",
    "\n",
    "vectors = np.load(VECTOR_PATH + '_cut' + \".npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(846239, 384)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.rapids.ai/api/cuml/stable/api.html\n",
    "import cudf\n",
    "from cuml import UMAP\n",
    "from cuml.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to do: normalize vectors (umap uses euclidean metric)  ->  updated using https://github.com/rapidsai/cuml/issues/1653"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_num = 159"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((846239, 384), numpy.float32, 4)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors.shape, type(vectors[0][0]), np.dtype(np.float32).itemsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = vectors\n",
    "a_cudf = cudf.DataFrame(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = NearestNeighbors(n_neighbors=comp_num, metric='cosine')\n",
    "m.fit(a_cudf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_graph = m.kneighbors_graph(a_cudf, mode='distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = UMAP(n_components=comp_num)\n",
    "new_vectors_cudf = u.fit_transform(a_cudf, knn_graph=knn_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_vectors_cudf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [91]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m new_vectors \u001b[38;5;241m=\u001b[39m \u001b[43mnew_vectors_cudf\u001b[49m\u001b[38;5;241m.\u001b[39mto_numpy()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'new_vectors_cudf' is not defined"
     ]
    }
   ],
   "source": [
    "new_vectors = new_vectors_cudf.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "UMAP_PATH = '/mnt/ess_storage/DN_1/storage/home/akorneev/temp_tables/umap_vectors'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(UMAP_PATH + '_cut', new_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#try:\n",
    "#    new_vectors = np.load(UMAP_PATH)\n",
    "#except:\n",
    "#    new_vectors = umap_model.fit_transform(vectors, knn_graph=knn_graph)\n",
    "#    np.save(UMAP_PATH, new_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(846239, 159)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 vectors clustering to define topics (Used with 'rapids' kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.0 Functions to look for key words from clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.0.1 Tf-Idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer  \n",
    "\n",
    "transformer = TfidfTransformer()\n",
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keywords_from_cluster_tfidf(labels_, df, top_k):\n",
    "    assert(len(labels_) == df.shape[0])\n",
    "    print('Labels and df are acceptable')\n",
    "\n",
    "    try:\n",
    "        df_an.insert(0, 'label', np.nan)\n",
    "        print('Column is inserted')\n",
    "    except:\n",
    "        print('Label column exists')\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        if index % 100000 == 0:\n",
    "            print(index, '/', df.shape[0])\n",
    "        df.at[index, 'label'] = labels_[index]\n",
    "    # ensure about space in the end in order to use sum()\n",
    "    df['caption'] = df['caption'] + ' '\n",
    "    print('Df is updated')\n",
    "\n",
    "    corpus = list()\n",
    "    for lab in set(labels_):\n",
    "        if lab % 10 == 0:\n",
    "            print('lab', lab, '/', len(set(labels_)))\n",
    "        corpus.append(str(df[df.label == lab].caption.sum()).lower())\n",
    "\n",
    "    print('Corpus is ready')\n",
    "    vec = vectorizer.fit_transform(corpus)\n",
    "\n",
    "    print('Vectorizer is ready')\n",
    "    tfidf = transformer.fit_transform(vec)\n",
    "\n",
    "    print('Finishing...')\n",
    "    words = vectorizer.get_feature_names_out() \n",
    "    weight = tfidf.toarray() \n",
    "\n",
    "    for id, lab in enumerate(set(labels_)):\n",
    "        nums = weight[id].argsort()[-top_k:]\n",
    "        print(\"lab\", lab, \":\", [words[i] for i in nums])\n",
    "        \n",
    "    return words, weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tfidf function testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'caption': ['I like to eat sushi products animal', 'buy I magazine letter text newspapers', 'Sea products and sushi eat I',\n",
    "                 'Newspapers and journals buy text', 'sport football in text cup basketball'], 'ran': [3, 4, 4 , 5, 2]}\n",
    "\n",
    "df1 = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels and df are acceptable\n",
      "Label column exists\n",
      "0 / 5\n",
      "Df is updated\n",
      "lab 0 / 3\n",
      "Corpus is ready\n",
      "Vectorizer is ready\n",
      "Finishing...\n",
      "lab 0 : ['eat', 'products', 'sushi']\n",
      "lab 1 : ['text', 'buy', 'newspapers']\n",
      "lab 2 : ['basketball', 'sport', 'in']\n"
     ]
    }
   ],
   "source": [
    "wo, we = get_keywords_from_cluster_tfidf([0, 1, 0, 1, 2], df1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>and</th>\n",
       "      <th>animal</th>\n",
       "      <th>basketball</th>\n",
       "      <th>buy</th>\n",
       "      <th>cup</th>\n",
       "      <th>eat</th>\n",
       "      <th>football</th>\n",
       "      <th>in</th>\n",
       "      <th>journals</th>\n",
       "      <th>letter</th>\n",
       "      <th>like</th>\n",
       "      <th>magazine</th>\n",
       "      <th>newspapers</th>\n",
       "      <th>products</th>\n",
       "      <th>sea</th>\n",
       "      <th>sport</th>\n",
       "      <th>sushi</th>\n",
       "      <th>text</th>\n",
       "      <th>to</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.186785</td>\n",
       "      <td>0.2456</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.4912</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2456</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.4912</td>\n",
       "      <td>0.2456</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.4912</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.204048</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.536596</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.268298</td>\n",
       "      <td>0.268298</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.268298</td>\n",
       "      <td>0.536596</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.408095</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.423394</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.423394</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.423394</td>\n",
       "      <td>0.423394</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.423394</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.322002</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        and  animal  basketball       buy       cup     eat  football  \\\n",
       "0  0.186785  0.2456    0.000000  0.000000  0.000000  0.4912  0.000000   \n",
       "1  0.204048  0.0000    0.000000  0.536596  0.000000  0.0000  0.000000   \n",
       "2  0.000000  0.0000    0.423394  0.000000  0.423394  0.0000  0.423394   \n",
       "\n",
       "         in  journals    letter    like  magazine  newspapers  products  \\\n",
       "0  0.000000  0.000000  0.000000  0.2456  0.000000    0.000000    0.4912   \n",
       "1  0.000000  0.268298  0.268298  0.0000  0.268298    0.536596    0.0000   \n",
       "2  0.423394  0.000000  0.000000  0.0000  0.000000    0.000000    0.0000   \n",
       "\n",
       "      sea     sport   sushi      text      to  \n",
       "0  0.2456  0.000000  0.4912  0.000000  0.2456  \n",
       "1  0.0000  0.000000  0.0000  0.408095  0.0000  \n",
       "2  0.0000  0.423394  0.0000  0.322002  0.0000  "
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(we, columns=wo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.0.2 BERT based cosine similarity approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keywords_from_cluster_bert(labels_, df, original_vectors, umap_vectors, cluster_centers, top_k):\n",
    "    #assert(len(labels_) == df.shape[0])\n",
    "    #print('Labels and df are acceptable')\n",
    "\n",
    "    assert(len(original_vectors) == len(original_vectors))\n",
    "    print('Original and UMAP vectors are acceptable')\n",
    "    \n",
    "    #try:\n",
    "    #   df_an.insert(0, 'label', np.nan)\n",
    "    #    print('Column is inserted')\n",
    "    #except:\n",
    "    #    print('Label column exists')\n",
    "    \n",
    "    #for index, row in df.iterrows():\n",
    "    #    if index % 100000 == 0:\n",
    "    #        print(index, '/', df.shape[0])\n",
    "    #    df.at[index, 'label'] = labels_[index]\n",
    "    \n",
    "    # looking for UMAP vectors, which are closest to cluster central ones\n",
    "    cluster_center_vectors = dict()\n",
    "    for cluster_index, cluster_center in enumerate(cluster_centers):\n",
    "        max_dist = 2\n",
    "        max_index = 0\n",
    "        for vector_index, umap_vector in enumerate(umap_vectors):\n",
    "            dist = distance.cosine(cluster_center, umap_vector)\n",
    "            if dist < max_dist:\n",
    "                max_dist = dist\n",
    "                max_index = vector_index\n",
    "        cluster_center_vectors[cluster_index] = (max_index, max_dist)\n",
    "        print('For cluster', cluster_index, ' -> ', cluster_center_vectors[cluster_index])\n",
    "    \n",
    "    # obtaining original vectors that corresponds to UMAP vectors\n",
    "    \n",
    "    # tokenize captions\n",
    "    \n",
    "    # create embedding for each token\n",
    "    \n",
    "    # looking for top_k similar tokens to original vectors\n",
    "    \n",
    "    return cluster_center_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original and UMAP vectors are acceptable\n",
      "For cluster 0  ->  (227650, 0.0018498897552490234)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [336]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_keywords_from_cluster_bert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkmeans_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabels_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_cut\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvectors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_vectors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkmeans_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcluster_centers_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [335]\u001b[0m, in \u001b[0;36mget_keywords_from_cluster_bert\u001b[0;34m(labels_, df, original_vectors, umap_vectors, cluster_centers, top_k)\u001b[0m\n\u001b[1;32m     23\u001b[0m max_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m vector_index, umap_vector \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(umap_vectors):\n\u001b[0;32m---> 25\u001b[0m     dist \u001b[38;5;241m=\u001b[39m \u001b[43mdistance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcosine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcluster_center\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumap_vector\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dist \u001b[38;5;241m<\u001b[39m max_dist:\n\u001b[1;32m     27\u001b[0m         max_dist \u001b[38;5;241m=\u001b[39m dist\n",
      "File \u001b[0;32m~/.conda/envs/rapids-22.02/lib/python3.8/site-packages/scipy/spatial/distance.py:678\u001b[0m, in \u001b[0;36mcosine\u001b[0;34m(u, v, w)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;124;03mCompute the Cosine distance between 1-D arrays.\u001b[39;00m\n\u001b[1;32m    638\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    673\u001b[0m \n\u001b[1;32m    674\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;66;03m# cosine distance is also referred to as 'uncentered correlation',\u001b[39;00m\n\u001b[1;32m    676\u001b[0m \u001b[38;5;66;03m#   or 'reflective correlation'\u001b[39;00m\n\u001b[1;32m    677\u001b[0m \u001b[38;5;66;03m# clamp the result to 0-2\u001b[39;00m\n\u001b[0;32m--> 678\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mmin\u001b[39m(\u001b[43mcorrelation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcentered\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m, \u001b[38;5;241m2.0\u001b[39m))\n",
      "File \u001b[0;32m~/.conda/envs/rapids-22.02/lib/python3.8/site-packages/scipy/spatial/distance.py:630\u001b[0m, in \u001b[0;36mcorrelation\u001b[0;34m(u, v, w, centered)\u001b[0m\n\u001b[1;32m    628\u001b[0m uu \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maverage(np\u001b[38;5;241m.\u001b[39msquare(u), weights\u001b[38;5;241m=\u001b[39mw)\n\u001b[1;32m    629\u001b[0m vv \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maverage(np\u001b[38;5;241m.\u001b[39msquare(v), weights\u001b[38;5;241m=\u001b[39mw)\n\u001b[0;32m--> 630\u001b[0m dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m uv \u001b[38;5;241m/\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43muu\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;66;03m# Return absolute value to avoid small negative value due to rounding\u001b[39;00m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mabs(dist)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "get_keywords_from_cluster_bert(kmeans_model.labels_, df_cut, vectors, new_vectors, kmeans_model.cluster_centers_, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((843993, 159), (843993, 384), (100, 159), (843993, 13))"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_vectors.shape, vectors.shape, kmeans_model.cluster_centers_.shape, df_cut.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0018498897552490234,\n",
       " '#SedgwickBand @otis_plays_music @theboweryelectric @bridgingthemusic #minifest #rocknroll #blues #musiciansofinstagram #musicianslife #willvaultzphotography')"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance.cosine(kmeans_model.cluster_centers_[0], new_vectors[227650]), df_cut.iloc[227650].caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance.cosine([1], [-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1 HDBSCAN (to find number of classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HDBSCAN + UMAP https://towardsdatascience.com/clustering-sentence-embeddings-to-identify-intents-in-short-text-48d22d3bf02e\n",
    "from cuml.cluster import HDBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdbscan_model = HDBSCAN(min_cluster_size = 10, max_cluster_size = 20000, metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label prop iterations: 50\n",
      "Label prop iterations: 8\n",
      "Label prop iterations: 11\n",
      "Label prop iterations: 7\n",
      "Label prop iterations: 3\n",
      "Label prop iterations: 2\n",
      "Iterations: 6\n",
      "32586,438,34102,26,870,62487\n",
      "Label prop iterations: 2\n",
      "Iterations: 1\n",
      "2836,139,4388,14,157,187\n",
      "CPU times: user 4min 39s, sys: 2min 17s, total: 6min 57s\n",
      "Wall time: 6min 57s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HDBSCAN()"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "hdbscan_model.fit(new_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 989\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of classes:\", hdbscan_model.cluster_persistence_[0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noisy count: 664929 / 846239\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique( hdbscan_model.labels_, return_counts=True)\n",
    "print(\"Noisy count:\", dict(zip(unique, counts))[-1], '/', len(new_vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5077436, 10000)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_an), len(hdbscan_model.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set(hdbscan_model.labels_[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "# ~1.5 for 30000\n",
    "# ~3.5 for 50000\n",
    "#get_keywords_from_cluster(hdbscan_model.labels_, df_an[:10000], 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2 K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuml import KMeans\n",
    "from cuml.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_model = KMeans( n_clusters = 100 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans()"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans_model.fit(new_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels:\n",
      "[16 16 16 ... 16 16 16]\n",
      "cluster_centers:\n",
      "[[ -29.631062   -25.952377    13.173149  ...   -3.9463592    7.160551\n",
      "    -0.6754093]\n",
      " [  -1.8572608  -13.249252     3.9118426 ...   -1.0331135    2.4056315\n",
      "    -1.5349947]\n",
      " [ 212.59457   -200.68294   -211.7191    ...  170.304      210.60962\n",
      "  -179.27914  ]\n",
      " ...\n",
      " [ -26.967728   -32.44268     31.338455  ...   29.954788   -25.900599\n",
      "    31.002636 ]\n",
      " [ -61.271828    45.47111     60.244064  ...  -41.965828   -34.58024\n",
      "    40.815666 ]\n",
      " [  11.210983    12.296383   -21.038128  ...  -26.82217     16.835262\n",
      "    30.25371  ]]\n"
     ]
    }
   ],
   "source": [
    "print(\"labels:\")\n",
    "print(kmeans_model.labels_)\n",
    "print(\"cluster_centers:\")\n",
    "print(kmeans_model.cluster_centers_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16, 16, 16, ..., 16, 16, 16], dtype=int32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans_model.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1,\n",
       " 1: 65,\n",
       " 2: 1,\n",
       " 3: 1,\n",
       " 4: 1,\n",
       " 5: 1,\n",
       " 6: 1,\n",
       " 7: 1,\n",
       " 8: 1,\n",
       " 9: 40,\n",
       " 10: 1,\n",
       " 11: 1,\n",
       " 12: 1,\n",
       " 13: 1,\n",
       " 14: 1,\n",
       " 15: 107,\n",
       " 16: 845929,\n",
       " 17: 1,\n",
       " 18: 1,\n",
       " 19: 1,\n",
       " 20: 1,\n",
       " 21: 1,\n",
       " 22: 1,\n",
       " 23: 1,\n",
       " 24: 1,\n",
       " 25: 1,\n",
       " 26: 1,\n",
       " 27: 1,\n",
       " 28: 1,\n",
       " 29: 1,\n",
       " 30: 1,\n",
       " 31: 1,\n",
       " 32: 1,\n",
       " 33: 1,\n",
       " 34: 1,\n",
       " 35: 1,\n",
       " 36: 1,\n",
       " 37: 1,\n",
       " 38: 1,\n",
       " 39: 1,\n",
       " 40: 1,\n",
       " 41: 1,\n",
       " 42: 1,\n",
       " 43: 1,\n",
       " 44: 1,\n",
       " 45: 1,\n",
       " 46: 1,\n",
       " 47: 1,\n",
       " 48: 1,\n",
       " 49: 1,\n",
       " 50: 1,\n",
       " 51: 1,\n",
       " 52: 1,\n",
       " 53: 1,\n",
       " 54: 1,\n",
       " 55: 1,\n",
       " 56: 1,\n",
       " 57: 1,\n",
       " 58: 1,\n",
       " 59: 1,\n",
       " 60: 1,\n",
       " 61: 1,\n",
       " 62: 1,\n",
       " 63: 1,\n",
       " 64: 3,\n",
       " 65: 1,\n",
       " 66: 1,\n",
       " 67: 1,\n",
       " 68: 1,\n",
       " 69: 1,\n",
       " 70: 1,\n",
       " 71: 1,\n",
       " 72: 1,\n",
       " 73: 1,\n",
       " 74: 1,\n",
       " 75: 1,\n",
       " 76: 1,\n",
       " 77: 1,\n",
       " 78: 1,\n",
       " 79: 1,\n",
       " 80: 1,\n",
       " 81: 1,\n",
       " 82: 1,\n",
       " 83: 1,\n",
       " 84: 1,\n",
       " 85: 1,\n",
       " 86: 1,\n",
       " 87: 1,\n",
       " 88: 1,\n",
       " 89: 1,\n",
       " 90: 1,\n",
       " 91: 1,\n",
       " 92: 1,\n",
       " 93: 1,\n",
       " 94: 1,\n",
       " 95: 1,\n",
       " 96: 1,\n",
       " 97: 1,\n",
       " 98: 1,\n",
       " 99: 1}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique, counts = np.unique( kmeans_model.labels_, return_counts=True)\n",
    "dict_clus_num = dict(zip(unique, counts))\n",
    "dict_clus_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.2.1 Looking for outliers using K-means clusters with small size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outliers(labels, min_cluster_size = 10):\n",
    "    unique, counts = np.unique( labels, return_counts=True)\n",
    "    dict_clus_num = dict(zip(unique, counts))\n",
    "    \n",
    "    outliers = [ id for id, lab in enumerate(labels) if dict_clus_num[lab] < min_cluster_size ]\n",
    "    \n",
    "    return outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((846239, 12), (846239, 159), (846239, 384))"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_vectors = new_vectors_backup\n",
    "vectors = vectors_backup\n",
    "df_cut = df_cut_backup.copy()\n",
    "df_cut.shape, new_vectors.shape, vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors_backup = vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_vectors_backup = new_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cut_backup = df_cut.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n",
      "delete  98  vectors \\ rows\n",
      "Iteration 1\n",
      "delete  97  vectors \\ rows\n",
      "Iteration 2\n",
      "delete  98  vectors \\ rows\n",
      "Iteration 3\n",
      "delete  100  vectors \\ rows\n",
      "Iteration 4\n",
      "delete  91  vectors \\ rows\n",
      "Iteration 5\n",
      "delete  104  vectors \\ rows\n",
      "Iteration 6\n",
      "delete  99  vectors \\ rows\n",
      "Iteration 7\n",
      "delete  98  vectors \\ rows\n",
      "Iteration 8\n",
      "delete  99  vectors \\ rows\n",
      "Iteration 9\n",
      "delete  98  vectors \\ rows\n",
      "Iteration 10\n",
      "delete  99  vectors \\ rows\n",
      "Iteration 11\n",
      "delete  99  vectors \\ rows\n",
      "Iteration 12\n",
      "delete  99  vectors \\ rows\n",
      "Iteration 13\n",
      "delete  105  vectors \\ rows\n",
      "Iteration 14\n",
      "delete  99  vectors \\ rows\n",
      "Iteration 15\n",
      "delete  98  vectors \\ rows\n",
      "Iteration 16\n",
      "delete  99  vectors \\ rows\n",
      "Iteration 17\n",
      "delete  99  vectors \\ rows\n",
      "Iteration 18\n",
      "delete  99  vectors \\ rows\n",
      "Iteration 19\n",
      "delete  98  vectors \\ rows\n",
      "Iteration 20\n",
      "delete  98  vectors \\ rows\n",
      "Iteration 21\n",
      "delete  97  vectors \\ rows\n",
      "Iteration 22\n",
      "delete  42  vectors \\ rows\n",
      "Iteration 23\n",
      "delete  23  vectors \\ rows\n",
      "Iteration 24\n",
      "delete  7  vectors \\ rows\n",
      "Iteration 25\n",
      "delete  3  vectors \\ rows\n",
      "Iteration 26\n",
      "break\n",
      "CPU times: user 57.3 s, sys: 2min 5s, total: 3min 2s\n",
      "Wall time: 3min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "i = 0\n",
    "while( True ):\n",
    "    print('Iteration', i)\n",
    "    \n",
    "    kmeans_model = KMeans( n_clusters = 100 )\n",
    "    kmeans_model.fit(new_vectors)\n",
    "    \n",
    "    outl = get_outliers(kmeans_model.labels_)\n",
    "\n",
    "    if len(outl) != 0:\n",
    "        print('delete ', len(outl), ' vectors \\ rows')\n",
    "        new_vectors = np.delete(new_vectors, outl, 0)\n",
    "        vectors = np.delete(vectors, outl, 0)\n",
    "        df_cut = df_cut.drop(outl).reset_index().drop('index', axis = 1)\n",
    "        i += 1\n",
    "    else:\n",
    "        print('break')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2246  elements are deleted\n"
     ]
    }
   ],
   "source": [
    "print( - len(new_vectors) + len(new_vectors_backup), ' elements are deleted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans()"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans_model = KMeans( n_clusters = 100 )\n",
    "kmeans_model.fit(new_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 17640,\n",
       " 1: 2423,\n",
       " 2: 11017,\n",
       " 3: 11775,\n",
       " 4: 7666,\n",
       " 5: 2161,\n",
       " 6: 2721,\n",
       " 7: 11770,\n",
       " 8: 2600,\n",
       " 9: 13610,\n",
       " 10: 14756,\n",
       " 11: 1669,\n",
       " 12: 5054,\n",
       " 13: 14217,\n",
       " 14: 10452,\n",
       " 15: 8672,\n",
       " 16: 7598,\n",
       " 17: 5084,\n",
       " 18: 12956,\n",
       " 19: 9506,\n",
       " 20: 1105,\n",
       " 21: 3102,\n",
       " 22: 13450,\n",
       " 23: 11744,\n",
       " 24: 18537,\n",
       " 25: 4097,\n",
       " 26: 8999,\n",
       " 27: 11414,\n",
       " 28: 8347,\n",
       " 29: 12463,\n",
       " 30: 6888,\n",
       " 31: 17636,\n",
       " 32: 12288,\n",
       " 33: 3515,\n",
       " 34: 7365,\n",
       " 35: 6334,\n",
       " 36: 8845,\n",
       " 37: 3705,\n",
       " 38: 2442,\n",
       " 39: 10910,\n",
       " 40: 11534,\n",
       " 41: 18042,\n",
       " 42: 20565,\n",
       " 43: 18696,\n",
       " 44: 8926,\n",
       " 45: 218,\n",
       " 46: 13850,\n",
       " 47: 18482,\n",
       " 48: 6339,\n",
       " 49: 7405,\n",
       " 50: 294,\n",
       " 51: 8943,\n",
       " 52: 11065,\n",
       " 53: 9604,\n",
       " 54: 6601,\n",
       " 55: 544,\n",
       " 56: 7342,\n",
       " 57: 6227,\n",
       " 58: 11999,\n",
       " 59: 9237,\n",
       " 60: 2267,\n",
       " 61: 7853,\n",
       " 62: 164,\n",
       " 63: 9861,\n",
       " 64: 12653,\n",
       " 65: 13051,\n",
       " 66: 4666,\n",
       " 67: 12274,\n",
       " 68: 5783,\n",
       " 69: 10404,\n",
       " 70: 12677,\n",
       " 71: 73,\n",
       " 72: 18885,\n",
       " 73: 3776,\n",
       " 74: 8291,\n",
       " 75: 15626,\n",
       " 76: 6133,\n",
       " 77: 2633,\n",
       " 78: 12308,\n",
       " 79: 11090,\n",
       " 80: 13080,\n",
       " 81: 7119,\n",
       " 82: 14741,\n",
       " 83: 13171,\n",
       " 84: 8889,\n",
       " 85: 2498,\n",
       " 86: 362,\n",
       " 87: 188,\n",
       " 88: 6659,\n",
       " 89: 746,\n",
       " 90: 9117,\n",
       " 91: 14182,\n",
       " 92: 9865,\n",
       " 93: 142,\n",
       " 94: 3491,\n",
       " 95: 8220,\n",
       " 96: 6204,\n",
       " 97: 8591,\n",
       " 98: 42,\n",
       " 99: 3772}"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique, counts = np.unique( kmeans_model.labels_, return_counts=True)\n",
    "dict_clus_num = dict(zip(unique, counts))\n",
    "dict_clus_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_keywords_from_cluster_tfidf(kmeans_model.labels_, df_cut, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.3 Agglomerative Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 quantization analysis for obtained clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Similarity calculating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_time(time1, time2):\n",
    "    # check wich cluster it is, chose time shift\n",
    "    return 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_space(space1, space2):\n",
    "    # check wich cluster it is, chose space shift\n",
    "    return 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_semantic(text1, text2):\n",
    "    return 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarity(row1, row2):\n",
    "    # + реклама\n",
    "    total = connect_time(row1.timestamp, row2.timestamp) + connect_space((row1.lat, row1.lon), (row2.lat, row2.lon)) + connect_semantic(row1.caption, row2.caption)\n",
    "    return float (total) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_similarity(df_an.iloc[0], df_an.iloc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# граф со связкой аномалий?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids",
   "language": "python",
   "name": "rapids-22.02"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
